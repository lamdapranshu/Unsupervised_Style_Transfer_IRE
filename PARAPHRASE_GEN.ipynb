{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xNa7qTsUorb"
      },
      "outputs": [],
      "source": [
        "# Using DVP, paraphrase the sentences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ IMP ----------------------\n",
        "# Comment data shortening line while paraphrasing datafiles\n",
        "# Change batch size if needed"
      ],
      "metadata": {
        "id": "mGN-6pdhyqFk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Transformers\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FHE2uiJVMll",
        "outputId": "e14d1601-10e5-4f55-8434-4ac32b01f14f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Desired imports\n",
        "import torch\n",
        "import tqdm\n",
        "from tqdm import trange\n",
        "from transformers import (WEIGHTS_NAME, AdamW, GPT2Config, GPT2LMHeadModel, GPT2Tokenizer, get_linear_schedule_with_warmup)\n",
        "import json\n",
        "import glob\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "MD9KPg14VOtu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directories needed\n",
        "final_paraphrase_model_dir = \"/content/drive/MyDrive/IRE/DVP/final_DVP\"\n",
        "data_to_paraphrased_dirs = \"/content/drive/MyDrive/IRE/DVP_PARAPHRASED\""
      ],
      "metadata": {
        "id": "FQFUd0eWUyJx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpus = torch.cuda.device_count()\n",
        "\n",
        "print(\"Device- \", device)\n",
        "print(\"No. of GPUs- \", n_gpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiSGmc4bVuwh",
        "outputId": "381b7134-9b1a-4abd-c805-ebabae2c7fbc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device-  cpu\n",
            "No. of GPUs-  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model, tokenizer and arguments\n",
        "\n",
        "# Initialize model classes variables\n",
        "MODEL_CLASSES = {\n",
        "    'gpt2': (GPT2Config, GPT2LMHeadModel, GPT2Tokenizer),\n",
        "}\n",
        "_, model_class, tokenizer_class = MODEL_CLASSES[\"gpt2\"]\n",
        "\n",
        "print(\"GPT2 Model class- \", model_class)\n",
        "print(\"GPT2 Tokenizer class- \", tokenizer_class)\n",
        "\n",
        "chkpt_to_load = final_paraphrase_model_dir\n",
        "paraphraser = model_class.from_pretrained(chkpt_to_load)\n",
        "tokenizer = tokenizer_class.from_pretrained(chkpt_to_load, do_lower_case = True)\n",
        "\n",
        "paraphraser.to(device)\n",
        "\n",
        "print(\"Diverse Paraphraser loaded along with the desired tokenizer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBqaZJz7U585",
        "outputId": "45a3343c-1cf7-4514-8122-42e64fcdb415"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2 Model class-  <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>\n",
            "GPT2 Tokenizer class-  <class 'transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diverse Paraphraser loaded along with the desired tokenizer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables needed for paraphrasing\n",
        "upper_length = \"same_5\" # change last value like _10, _15\n",
        "temparature = 0\n",
        "device = device\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "F0c-3yZzVluX"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Init configs\n",
        "\n",
        "MAX_PARAPHRASE_LEN = 100\n",
        "\n",
        "# mainly to handle input\n",
        "INPUT_FORMAT_CONFIG = {\n",
        "    \"max_prefix_length\": int(MAX_PARAPHRASE_LEN / 2),\n",
        "    \"max_suffix_length\": int(MAX_PARAPHRASE_LEN / 2)\n",
        "}"
      ],
      "metadata": {
        "id": "y_iC2uLMzBKS"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do Nucleas sampling and greedy decoding; vary top_p to consider more diversity\n",
        "def top_k_top_p_filtering(logits, top_k = 0, top_p = 0.0, filter_amt = -float('Inf')):\n",
        "  top_k = min(top_k, logits.size(-1))  # tok_k should be less than total vocab size\n",
        "\n",
        "  if top_p > 0.0:\n",
        "      sorted_logits, sorted_idxs = torch.sort(logits, descending=True)\n",
        "      cumul_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "\n",
        "      # Remove tokens with cumulative probability above the threshold\n",
        "      sorted_idxs_to_remove = cumul_probs > top_p\n",
        "\n",
        "      # Shift the indices to the right to keep also the first token above the threshold\n",
        "      sorted_idxs_to_remove[..., 1:] = sorted_idxs_to_remove[..., :-1].clone()\n",
        "      sorted_idxs_to_remove[..., 0] = 0\n",
        "\n",
        "      # scatter sorted tensors to original indexing\n",
        "      indices_to_remove = sorted_idxs_to_remove.scatter(dim = 1, index = sorted_idxs, src = sorted_idxs_to_remove)\n",
        "      logits[indices_to_remove] = filter_amt\n",
        "\n",
        "  elif top_k > 0:\n",
        "      # Remove all tokens with a probability less than the last token of the top_k\n",
        "      indices_to_remove = logits < torch.topk(logits, int(top_k))[0][..., -1, None]\n",
        "      logits[indices_to_remove] = filter_amt\n",
        "\n",
        "  return logits"
      ],
      "metadata": {
        "id": "7heI0WpPYqXG"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get output logits from paraphraser\n",
        "def get_logits(paraphraser, idx, sents, segments, past):\n",
        "  if idx == 0:\n",
        "      pred = paraphraser(input_ids = sents, token_type_ids = segments, return_dict=True)\n",
        "  else:\n",
        "      # used the cached representations to speed up decoding\n",
        "      print(\"Logits to calculate of shape- \", sents[:, -1:].shape)\n",
        "      pred = paraphraser(input_ids = sents[:, -1:], token_type_ids = segments[:, -1:], past_key_values = past, return_dict = True)\n",
        "\n",
        "  logits = pred['logits']\n",
        "  past_keys = pred['past_key_values']\n",
        "\n",
        "  return logits, past_keys"
      ],
      "metadata": {
        "id": "YYy7ChcHzL9U"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decide generation lenght and get converted output and score\n",
        "def generate(paraphraser, sents_to_paraphrase, segments, eos_token_id, top_p, top_k, len_to_gen):\n",
        "  batch_size = sents_to_paraphrase.shape[0] # total sents in batch\n",
        "  print(\"batch size- \", batch_size)\n",
        "\n",
        "  eos_emitted = [False for _ in range(batch_size)]\n",
        "  scores = [{\"score\": 0, \"sequence\": []} for _ in range(batch_size)]\n",
        "  print(\"sents to rephrase- \", sents_to_paraphrase)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    past_keys = None\n",
        "\n",
        "    for i in range(len_to_gen):\n",
        "      op_logits, past_keys = get_logits(paraphraser, i, sents_to_paraphrase, segments, past_keys)\n",
        "      print(\"op_logits shape- \", op_logits.shape)\n",
        "\n",
        "      next_token_logits = op_logits[:, -1, :]\n",
        "      print(\"next token logits of shape- \", next_token_logits.shape)\n",
        "      original_scores = F.log_softmax(next_token_logits, dim = -1)\n",
        "\n",
        "      # do nucleas filtering and greedy decoding\n",
        "      filtered_logits = top_k_top_p_filtering(next_token_logits, top_k = top_k, top_p = top_p)\n",
        "      print(\"filtered_logits of shape- \", filtered_logits.shape)\n",
        "\n",
        "      if top_k in [0, 1] and top_p == 0.0: # mainly to control the output diversity\n",
        "        # greedy sampling\n",
        "        next_token = torch.argmax(filtered_logits, dim = -1).unsqueeze(-1)\n",
        "      else :\n",
        "        next_token = torch.multinomial(F.softmax(filtered_logits, dim=-1), num_samples = 1)\n",
        "\n",
        "      print(\"next token- \", next_token, \" and of shape- \", next_token.shape)\n",
        "\n",
        "      for batch_elem in range(batch_size):\n",
        "          if eos_emitted[batch_elem]:\n",
        "              continue\n",
        "          scores[batch_elem][\"score\"] += original_scores[batch_elem, next_token[batch_elem].item()].item()\n",
        "          scores[batch_elem][\"sequence\"].append(\"token\")\n",
        "\n",
        "      sents_to_paraphrase = torch.cat((sents_to_paraphrase, next_token), dim=1)\n",
        "      segments = torch.cat((segments, segments[:, -1:]), dim=1)\n",
        "\n",
        "      print(\"concat sents to change- \", sents_to_paraphrase, \" and of shape- \", sents_to_paraphrase.shape)\n",
        "\n",
        "      for batch_elem in range(batch_size):\n",
        "        if next_token[batch_elem].item() == eos_token_id:\n",
        "            eos_emitted[batch_elem] = True\n",
        "\n",
        "      if len_to_gen is None and all(eos_emitted):\n",
        "        break\n",
        "\n",
        "  scores = [x[\"score\"] / len(x[\"sequence\"]) for x in scores]\n",
        "\n",
        "  return sents_to_paraphrase, scores"
      ],
      "metadata": {
        "id": "yPs0wasPq4au"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess input from to paraphrase\n",
        "def preprocess(exp, tokenizer, config, do_tokenize = True):\n",
        "  max_prefix_len = config[\"max_prefix_length\"]\n",
        "  sent1 = np.array(exp[\"sent1_tokens\"])\n",
        "\n",
        "  # truncate\n",
        "  if(len(sent1) > max_prefix_len):\n",
        "    sent1 = sent1[:max_prefix_len]\n",
        "\n",
        "  # add padding; left padding to prefix and right padding to suffix\n",
        "  count_pad_tokens_prefix = max_prefix_len - len(sent1)\n",
        "  sent1 = np.pad(sent1, (count_pad_tokens_prefix, 0), constant_values = tokenizer.pad_token_id)\n",
        "\n",
        "  # sentence to input gpt2\n",
        "  sentence_to_input_gpt2 = np.concatenate([sent1, [tokenizer.bos_token_id]]).astype(np.int64) # [sent1, <bos>]\n",
        "\n",
        "  # segment\n",
        "  segment = np.concatenate([\n",
        "      [tokenizer.additional_special_tokens_ids[0] for _ in sent1],\n",
        "      [tokenizer.additional_special_tokens_ids[1]]\n",
        "  ]).astype(np.int64)\n",
        "\n",
        "  exp[\"input\"] = sentence_to_input_gpt2\n",
        "  exp[\"segment\"] = segment\n",
        "\n",
        "  return exp"
      ],
      "metadata": {
        "id": "W5qaIeJZrj2R"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate paraphrased sentences for batch of input sentences\n",
        "def generate_paraphrased_sents_batchwise(paraphraser, upper_length, top_p, top_k, sents, config, device, tokenizer):\n",
        "  examples = []\n",
        "\n",
        "  for sent in sents:\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sent))\n",
        "    dd = {\"sent1_tokens\":token_ids}\n",
        "\n",
        "    dd_process = preprocess(dd, tokenizer, config, do_tokenize = False)\n",
        "    examples.append(dd_process)\n",
        "\n",
        "  init_context_size = 1 + config[\"max_prefix_length\"]\n",
        "\n",
        "  print(\"example to paraphrase-0 \", examples[0])\n",
        "\n",
        "  output, scores = generate(paraphraser,\n",
        "      sents_to_paraphrase = torch.tensor([inst[\"input\"] for inst in examples]).to(device),\n",
        "      segments = torch.tensor([inst[\"segment\"] for inst in examples]).to(device),\n",
        "      eos_token_id = tokenizer.eos_token_id,\n",
        "      top_p = top_p, top_k = top_k,\n",
        "      len_to_gen =  config[\"max_suffix_length\"] + 1  # +1 for <eos>\n",
        "  )\n",
        "\n",
        "  all_ops = []\n",
        "  for idx in range(len(output)):\n",
        "    exmp = examples[idx]\n",
        "    curr_out = output[idx, init_context_size:].tolist()\n",
        "\n",
        "    if tokenizer.eos_token_id in curr_out:\n",
        "      curr_out = curr_out[:curr_out.index(tokenizer.eos_token_id)]\n",
        "\n",
        "    if upper_length.startswith(\"same\"):\n",
        "      extra = int(upper_length.split(\"_\")[-1])\n",
        "      curr_out = curr_out[:len(exmp[\"sent1_tokens\"]) + extra]\n",
        "\n",
        "    all_ops.append(tokenizer.decode(curr_out, clean_up_tokenization_spaces = True, skip_special_tokens = True))\n",
        "\n",
        "  return all_ops, scores"
      ],
      "metadata": {
        "id": "l8l2sohErWUC"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "database_config = {\n",
        "    \"shakespeare\" : (data_to_paraphrased_dirs + \"/shakespeare_data\", 0.0, 1.0), # (data_dir, top_p, top_k)\n",
        "    \"bible\" : (data_to_paraphrased_dirs + \"/bible_data\", 0.0, 1.0),\n",
        "    \"poetry\" : (data_to_paraphrased_dirs + \"/poetry_data\", 0.0, 1.0)\n",
        "}"
      ],
      "metadata": {
        "id": "9IlLQLm3t5FH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "database_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoNdmhalF5uX",
        "outputId": "378779f5-3d98-4293-d21a-88f40c2df019"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'shakespeare': ('/content/drive/MyDrive/IRE/DVP_PARAPHRASED/shakespeare_data',\n",
              "  0.0,\n",
              "  1.0),\n",
              " 'bible': ('/content/drive/MyDrive/IRE/DVP_PARAPHRASED/bible_data', 0.0, 1.0),\n",
              " 'poetry': ('/content/drive/MyDrive/IRE/DVP_PARAPHRASED/poetry_data',\n",
              "  0.0,\n",
              "  1.0)}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert sentences to their paraphrased version and saved\n",
        "for dataset_name, dataset_config in database_config.items():\n",
        "  print(\"Starting paraphrasing for \", dataset_name)\n",
        "\n",
        "  for split in [\"train\", \"test\", \"dev\"]:\n",
        "    file_dir = dataset_config[0] + \"/\" + split + \".txt\"\n",
        "    top_p = dataset_config[1]\n",
        "    top_k = dataset_config[2]\n",
        "\n",
        "    with open(file_dir, \"r\") as f:\n",
        "      data = f.read().strip().split(\"\\n\")\n",
        "\n",
        "    # FOR PIPELINE TESTING PURPOSE\n",
        "    data = data[:1]\n",
        "\n",
        "    paraphrased_sents = []\n",
        "    for i in tqdm.tqdm(range(0, len(data), batch_size)):\n",
        "        generations, scores = generate_paraphrased_sents_batchwise(paraphraser, upper_length, top_p, top_k, data[i:i + batch_size], INPUT_FORMAT_CONFIG, device, tokenizer)\n",
        "        paraphrased_sents.extend(generations)\n",
        "\n",
        "    print(split + \" Sentences paraphrased for \", dataset_name)\n",
        "\n",
        "    # save file\n",
        "    fname = dataset_config[0] + \"/\" + split + \".dvp_paraphrased.txt\"\n",
        "    with open(fname, \"w\") as f:\n",
        "      f.write(\"\\n\".join(paraphrased_sents) + \"\\n\")\n",
        "\n",
        "    print(split + \" Paraphrased sentences for \" + dataset_name + \" saved in file\")\n",
        "\n",
        "  print(\"Done paraphrasing for \", dataset_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8996JhyNs65E",
        "outputId": "d6d40d24-53b5-497b-dc0b-3852d5ab82c2"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting paraphrsing for  shakespeare\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example to paraphrase-0  {'sent1_tokens': [40, 423, 257, 2000, 284, 5587, 17903, 304, 260, 14210, 2740, 338, 83, 764], 'input': array([50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "          40,   423,   257,  2000,   284,  5587, 17903,   304,   260,\n",
            "       14210,  2740,   338,    83,   764, 50260]), 'segment': array([50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
            "       50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
            "       50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
            "       50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
            "       50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
            "       50257, 50257, 50257, 50257, 50257, 50258])}\n",
            "batch size-  1\n",
            "sents to rephrase-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260]])\n",
            "op_logits shape-  torch.Size([1, 51, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259]])  and of shape-  torch.Size([1, 52])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259]])  and of shape-  torch.Size([1, 53])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 54])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 55])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 56])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 57])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 58])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 59])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 60])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259]])  and of shape-  torch.Size([1, 61])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259]])  and of shape-  torch.Size([1, 62])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259]])  and of shape-  torch.Size([1, 63])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 64])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 65])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 66])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 67])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 68])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 69])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 70])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259]])  and of shape-  torch.Size([1, 71])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259]])  and of shape-  torch.Size([1, 72])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259]])  and of shape-  torch.Size([1, 73])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 74])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 75])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 76])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 77])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 78])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 79])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 80])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259]])  and of shape-  torch.Size([1, 81])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259]])  and of shape-  torch.Size([1, 82])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259]])  and of shape-  torch.Size([1, 83])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 84])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 85])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 86])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 87])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 88])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 89])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 90])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259]])  and of shape-  torch.Size([1, 91])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259]])  and of shape-  torch.Size([1, 92])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259]])  and of shape-  torch.Size([1, 93])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 94])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 95])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 96])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 97])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 98])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 99])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259]])  and of shape-  torch.Size([1, 100])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n",
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259]])  and of shape-  torch.Size([1, 101])\n",
            "Logits to calculate of shape-  torch.Size([1, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 1/1 [00:05<00:00,  5.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "op_logits shape-  torch.Size([1, 1, 50262])\n",
            "next token logits of shape-  torch.Size([1, 50262])\n",
            "filtered_logits of shape-  torch.Size([1, 50262])\n",
            "next token-  tensor([[50259]])  and of shape-  torch.Size([1, 1])\n",
            "concat sents to chnage-  tensor([[50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259,    40,   423,   257,  2000,\n",
            "           284,  5587, 17903,   304,   260, 14210,  2740,   338,    83,   764,\n",
            "         50260, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
            "         50259, 50259]])  and of shape-  torch.Size([1, 102])\n",
            "train Sentences paraphrased for  shakespeare\n",
            "train Paraphrased sentences for shakespeare saved in file\n",
            "Done paraphrasing for  shakespeare\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Till now,\n",
        "# Paraphrasing done for datasets in database_config for each split\n",
        "# Now convert to bpe files"
      ],
      "metadata": {
        "id": "sDuhJ-XUxfQC"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "# !pip install bitarray\n",
        "# !pip install sacrebleu"
      ],
      "metadata": {
        "id": "AnWPFsCN-zQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install hydra-core omegaconf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "EWWZHm1r8K2Z",
        "outputId": "af773a1c-647f-41d5-cfc0-842e91fb524a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hydra-core\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from hydra-core)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core) (23.2)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0.1)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=2062e0b4d10a2567358cf01bb528d70add88bcb0b360dc1832ad0e6b790a639c\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, omegaconf, hydra-core\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 omegaconf-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roberta = torch.hub.load('pytorch/fairseq', 'roberta.base')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0e1AVvC7gqX",
        "outputId": "7255b2fb-05fb-4cdf-fbd9-a50d5df0c28f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_fairseq_main\n",
            "100%|| 231160875/231160875 [00:04<00:00, 49655395.24B/s]\n",
            "/usr/local/lib/python3.10/dist-packages/hydra/experimental/initialize.py:43: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
            "  deprecation_warning(message=message)\n",
            "/usr/local/lib/python3.10/dist-packages/hydra/experimental/initialize.py:45: UserWarning: \n",
            "The version_base parameter is not specified.\n",
            "Please specify a compatability version level, or None.\n",
            "Will assume defaults for version 1.1\n",
            "  self.delegate = real_initialize(\n",
            "/usr/local/lib/python3.10/dist-packages/hydra/experimental/compose.py:25: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
            "  deprecation_warning(message=message)\n",
            "/usr/local/lib/python3.10/dist-packages/hydra/core/default_element.py:124: UserWarning: In 'config': Usage of deprecated keyword in package header '# @package _group_'.\n",
            "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
            "  deprecation_warning(\n",
            "/root/.cache/torch/hub/pytorch_fairseq_main/fairseq/checkpoint_utils.py:450: UserWarning: \n",
            "'config' is validated against ConfigStore schema with the same name.\n",
            "This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
            "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
            "  state = load_checkpoint_to_cpu(filename, arg_overrides)\n",
            "/usr/local/lib/python3.10/dist-packages/hydra/compose.py:56: UserWarning: \n",
            "The strict flag in the compose API is deprecated.\n",
            "See https://hydra.cc/docs/1.2/upgrades/0.11_to_1.0/strict_mode_flag_deprecated for more info.\n",
            "\n",
            "  deprecation_warning(\n",
            "/usr/local/lib/python3.10/dist-packages/hydra/experimental/initialize.py:43: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
            "  deprecation_warning(message=message)\n",
            "/usr/local/lib/python3.10/dist-packages/hydra/experimental/initialize.py:45: UserWarning: \n",
            "The version_base parameter is not specified.\n",
            "Please specify a compatability version level, or None.\n",
            "Will assume defaults for version 1.1\n",
            "  self.delegate = real_initialize(\n",
            "/root/.cache/torch/hub/pytorch_fairseq_main/fairseq/models/roberta/model.py:369: UserWarning: \n",
            "'config' is validated against ConfigStore schema with the same name.\n",
            "This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
            "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
            "  x = hub_utils.from_pretrained(\n",
            "1042301B [00:00, 22512280.33B/s]\n",
            "456318B [00:00, 13774380.62B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fn to convert data to byte pair encoding file\n",
        "def convert_to_bpe_and_save(data, fname, folder):\n",
        "  bpe_data = [roberta.bpe.encode(x) for x in tqdm.tqdm(data)]\n",
        "  with open(folder + \"/\" + fname, \"w\") as f:\n",
        "        f.write(\"\\n\".join(bpe_data) + \"\\n\")\n",
        "  return"
      ],
      "metadata": {
        "id": "q_Ql0NeJMv_m"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create BPE files for generated pseudo parellel data using Roberta\n",
        "for dataset_name, dataset_config in database_config.items():\n",
        "  print(\"Starting for \", dataset_name)\n",
        "\n",
        "  for split in [\"train\", \"dev\", \"test\"]:\n",
        "    bpe_folder = dataset_config[0] + \"/BPE\"\n",
        "    file_name_orig_abs = dataset_config[0] + \"/\" + split + \".txt\"\n",
        "    file_name_orig_paraphrased = dataset_config[0] + \"/\" + split + \".dvp_paraphrased.txt\"\n",
        "\n",
        "    with open(file_name_orig_abs, \"r\") as f:\n",
        "      data_orig = f.read().strip().split(\"\\n\")\n",
        "\n",
        "    with open(file_name_orig_paraphrased, \"r\") as f:\n",
        "      data_paraphrased = f.read().strip().split(\"\\n\")\n",
        "\n",
        "    # convert original file and paraphrased files to bpe folder after conversion to bpe format using roberta.base\n",
        "    convert_to_bpe_and_save(data_orig, split + \".input0.bpe\", bpe_folder)\n",
        "    convert_to_bpe_and_save(data_paraphrased, split + \".paraphrase_250_input0.bpe\", bpe_folder)\n",
        "\n",
        "    print(\"\\nDone conversion for \" + split + \" split for dataset- \" + dataset_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqeH1R7px-5F",
        "outputId": "ae484a14-1904-4b3d-a490-aaa9e1a708bf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting for  shakespeare\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 8/8 [00:00<00:00, 1305.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done conversion for train split for dataset- shakespeare\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Done paraphrasing"
      ],
      "metadata": {
        "id": "HBZ-IVu7Bx-P"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hack:-\n",
        "# We already have converted bpe files for every dataset; can directly use them for training inverse paraphraser\n",
        "# As we don't have raw data available directly to train the model\n",
        "# Only total of 1000 samples are there; which is very less and that also needs to be divided into train, test and dev splits.\n",
        "\n",
        "# available in /content/drive/MyDrive/IRE_Project/style_transfer_paraphrase/datasets/cds"
      ],
      "metadata": {
        "id": "odB2GVUJDdGq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finished paraphrasing"
      ],
      "metadata": {
        "id": "OCnVES2XGV-5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}