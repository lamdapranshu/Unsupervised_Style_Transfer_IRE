{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0f44080163d54e38aed66f007484175c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8ff9d30780eb456c952677f4364d3753","IPY_MODEL_88950eea00e942f6ae0468ceb33ac184","IPY_MODEL_86ed95915d42434791d2320ac4e6d3b5"],"layout":"IPY_MODEL_52a5f3474e1d4101a500abd6bde1cf1c"}},"8ff9d30780eb456c952677f4364d3753":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_632f45edd7584f87be38f566820bb484","placeholder":"​","style":"IPY_MODEL_4dc157d0245145faa6a454efd8374681","value":"config.json: 100%"}},"88950eea00e942f6ae0468ceb33ac184":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e847094cffd4dd0a8af7b0af5b5c4c7","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d441568a509047e69b1687a79c439c19","value":665}},"86ed95915d42434791d2320ac4e6d3b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15a61b449ada4256a6d93e473dc87a2d","placeholder":"​","style":"IPY_MODEL_407ac3699d1e408f98f18f347d961f25","value":" 665/665 [00:00&lt;00:00, 32.1kB/s]"}},"52a5f3474e1d4101a500abd6bde1cf1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"632f45edd7584f87be38f566820bb484":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dc157d0245145faa6a454efd8374681":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e847094cffd4dd0a8af7b0af5b5c4c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d441568a509047e69b1687a79c439c19":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15a61b449ada4256a6d93e473dc87a2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"407ac3699d1e408f98f18f347d961f25":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1843f8fdc24b4d71b7f519bf9a6a66b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0b31cd16ca0b4e669f8bc5da4d502550","IPY_MODEL_93e02cb8d66a47a18428d6e58000b33d","IPY_MODEL_430aee04583b4f80b90b725d98f744e8"],"layout":"IPY_MODEL_402527dcbda5455982a3df444c4bb76d"}},"0b31cd16ca0b4e669f8bc5da4d502550":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c889e051058c4e5881b54087f65a7efe","placeholder":"​","style":"IPY_MODEL_bec0e154fd524b29be1573b5e64c1ce9","value":"model.safetensors: 100%"}},"93e02cb8d66a47a18428d6e58000b33d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca7a5ac938374e9ba1d6d1713b528d40","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5833f09b0a9e4b7a8dc60c7a5f748a50","value":548105171}},"430aee04583b4f80b90b725d98f744e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_985223cbdf2f48c3bd74e4ead6e4d79b","placeholder":"​","style":"IPY_MODEL_7d961bf3ba2c4698a12db935cd01c317","value":" 548M/548M [00:04&lt;00:00, 136MB/s]"}},"402527dcbda5455982a3df444c4bb76d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c889e051058c4e5881b54087f65a7efe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bec0e154fd524b29be1573b5e64c1ce9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca7a5ac938374e9ba1d6d1713b528d40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5833f09b0a9e4b7a8dc60c7a5f748a50":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"985223cbdf2f48c3bd74e4ead6e4d79b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d961bf3ba2c4698a12db935cd01c317":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51ace3e986694237b14df616ee5e5e3e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bfaa532d9cc349daaf5adfc6965841ce","IPY_MODEL_e8dfa301d8d94d63a80ed23d5f2936f7","IPY_MODEL_3f388b450f1a4c73bd2595b03f3a30b0"],"layout":"IPY_MODEL_a2464e2c68ad4e48b9047771000a4442"}},"bfaa532d9cc349daaf5adfc6965841ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_375acaa4c35342adad27752c5eee5395","placeholder":"​","style":"IPY_MODEL_edfcfe8ade004b32a807ab59b305c1bf","value":"generation_config.json: 100%"}},"e8dfa301d8d94d63a80ed23d5f2936f7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e16080e29e345ab98188e4365986f7f","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1e9baf31a032472491ded50648ffa7d5","value":124}},"3f388b450f1a4c73bd2595b03f3a30b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3eac3d5427ba4ce08361f2d7679e85ea","placeholder":"​","style":"IPY_MODEL_4d3ef8a02dd54386a7891f97d530bf33","value":" 124/124 [00:00&lt;00:00, 2.50kB/s]"}},"a2464e2c68ad4e48b9047771000a4442":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"375acaa4c35342adad27752c5eee5395":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edfcfe8ade004b32a807ab59b305c1bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e16080e29e345ab98188e4365986f7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e9baf31a032472491ded50648ffa7d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3eac3d5427ba4ce08361f2d7679e85ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d3ef8a02dd54386a7891f97d530bf33":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6ed58c978cf4d65aa4689605073b2b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b59e91ad346e4872b472b55f19b44eea","IPY_MODEL_14a7e22cb00b4a5b95f6007499ac9ac4","IPY_MODEL_753ab3f4b1d649b58a3cb0bbd526dc4b"],"layout":"IPY_MODEL_1dd12f06c6624a31b86afa65eaee4f87"}},"b59e91ad346e4872b472b55f19b44eea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e32fd480efcc45ae87132f47f85de82f","placeholder":"​","style":"IPY_MODEL_86251c8dba3c4f16a38da11b269166d6","value":"vocab.json: 100%"}},"14a7e22cb00b4a5b95f6007499ac9ac4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_91a509b5bb7e4261acefc41e73528211","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d2d29271344643debccadff791a89f1e","value":1042301}},"753ab3f4b1d649b58a3cb0bbd526dc4b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_931903d110db4f71b4b7edbc0881e03c","placeholder":"​","style":"IPY_MODEL_4f4f6f4f49e04826a87d40c1eaa86596","value":" 1.04M/1.04M [00:00&lt;00:00, 4.46MB/s]"}},"1dd12f06c6624a31b86afa65eaee4f87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e32fd480efcc45ae87132f47f85de82f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86251c8dba3c4f16a38da11b269166d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91a509b5bb7e4261acefc41e73528211":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2d29271344643debccadff791a89f1e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"931903d110db4f71b4b7edbc0881e03c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f4f6f4f49e04826a87d40c1eaa86596":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83f5b1cc89a144c7b841547aebc24cb1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f2e7a5739872415c8829ecd80e12d6d9","IPY_MODEL_dd93cc2c02184cbaaf09103e89d0958f","IPY_MODEL_85af303f1cc244078289aa1c30f15f58"],"layout":"IPY_MODEL_2829a299613f49de9c8cbb5a07f631f2"}},"f2e7a5739872415c8829ecd80e12d6d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bf1dd2a1d7d4c4aa1dc7d341bd7098d","placeholder":"​","style":"IPY_MODEL_89ca6069e6b94e1abcb42689a32598a0","value":"merges.txt: 100%"}},"dd93cc2c02184cbaaf09103e89d0958f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec932e29b7c54558828be2bf7e710b77","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b29abab5938144849ae7d9eb831aafad","value":456318}},"85af303f1cc244078289aa1c30f15f58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7b1c384e9ce47628a8444e38d6175bd","placeholder":"​","style":"IPY_MODEL_2e796a49b63948929550fc31203ce967","value":" 456k/456k [00:00&lt;00:00, 5.38MB/s]"}},"2829a299613f49de9c8cbb5a07f631f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bf1dd2a1d7d4c4aa1dc7d341bd7098d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89ca6069e6b94e1abcb42689a32598a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec932e29b7c54558828be2bf7e710b77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b29abab5938144849ae7d9eb831aafad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c7b1c384e9ce47628a8444e38d6175bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e796a49b63948929550fc31203ce967":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96019b9b745d4c149c0c33f33d417a29":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6ab4cd29cf134537a8c100cc8cc42b79","IPY_MODEL_88b32110f5b2493bb6949da40a47c0fc","IPY_MODEL_dacdea0e299846e186e7f3420e85ac2a"],"layout":"IPY_MODEL_7d7a8adaf0c845b48a67fc3fad5f0a59"}},"6ab4cd29cf134537a8c100cc8cc42b79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a3ee327db0943319e518ed6003d1f62","placeholder":"​","style":"IPY_MODEL_51fd7298ccc04e5d88e966d575213847","value":"tokenizer.json: 100%"}},"88b32110f5b2493bb6949da40a47c0fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_231b27106952455fa9f1c30d3dfb2d89","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1ae9070c1f324b228dd7cca24859c09e","value":1355256}},"dacdea0e299846e186e7f3420e85ac2a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ad5e052ba124073a44437777ffaec43","placeholder":"​","style":"IPY_MODEL_5dec4383c6ac4415b4a68529c2ef73a0","value":" 1.36M/1.36M [00:00&lt;00:00, 16.3MB/s]"}},"7d7a8adaf0c845b48a67fc3fad5f0a59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a3ee327db0943319e518ed6003d1f62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51fd7298ccc04e5d88e966d575213847":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"231b27106952455fa9f1c30d3dfb2d89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ae9070c1f324b228dd7cca24859c09e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4ad5e052ba124073a44437777ffaec43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dec4383c6ac4415b4a68529c2ef73a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6993888,"sourceType":"datasetVersion","datasetId":4019925}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Structured DVP","metadata":{"id":"2c8SHLJDevAJ","execution":{"iopub.status.busy":"2023-11-18T18:24:59.671494Z","iopub.execute_input":"2023-11-18T18:24:59.671908Z","iopub.status.idle":"2023-11-18T18:24:59.678683Z","shell.execute_reply.started":"2023-11-18T18:24:59.671875Z","shell.execute_reply":"2023-11-18T18:24:59.677555Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# *********** IMP ************\n\n# Remove breaks frm training and validation loops\n# Change limit_examples argument value while creating train_dataset & val dataset and set it to None\n# While calculating the average train_loss; remove +1 from global_step (in denominator) while deletion\n# While saving the last model state, from that cell, remove global_step = 3\n# In training arguments; set model_name to gpt2-large\n# Change name of directories accordingly","metadata":{"id":"CNAhEa9axK-N","execution":{"iopub.status.busy":"2023-11-18T18:24:59.680670Z","iopub.execute_input":"2023-11-18T18:24:59.681079Z","iopub.status.idle":"2023-11-18T18:24:59.690669Z","shell.execute_reply.started":"2023-11-18T18:24:59.681041Z","shell.execute_reply":"2023-11-18T18:24:59.689811Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Importing Libraries","metadata":{}},{"cell_type":"code","source":"# Desired Imports\nimport torch\nimport tqdm\nfrom tqdm import trange\nfrom transformers import (AdamW, GPT2Config, GPT2LMHeadModel, GPT2Tokenizer, get_linear_schedule_with_warmup)\nfrom torch.utils.data import Dataset\nimport pickle\nimport numpy as np\nfrom collections import defaultdict\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler\nimport os\nimport shutil\nimport subprocess\nimport json\nimport torch.nn.utils as F\nfrom transformers import WEIGHTS_NAME\nimport glob","metadata":{"id":"MbjEd9Rne3I0","execution":{"iopub.status.busy":"2023-11-18T18:24:59.691706Z","iopub.execute_input":"2023-11-18T18:24:59.692095Z","iopub.status.idle":"2023-11-18T18:25:05.528191Z","shell.execute_reply.started":"2023-11-18T18:24:59.692063Z","shell.execute_reply":"2023-11-18T18:25:05.527359Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Creating Directories","metadata":{}},{"cell_type":"code","source":"paraphrase_model_chkpts_dir =  \"/kaggle/working/DVP\"\nfinal_paraphrase_model_dir = \"/kaggle/working/DVP/final_DVP\"\nos.makedirs(paraphrase_model_chkpts_dir, exist_ok=True)\nos.makedirs(final_paraphrase_model_dir, exist_ok=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:25:05.530232Z","iopub.execute_input":"2023-11-18T18:25:05.530626Z","iopub.status.idle":"2023-11-18T18:25:05.535849Z","shell.execute_reply.started":"2023-11-18T18:25:05.530599Z","shell.execute_reply":"2023-11-18T18:25:05.534820Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Specifying Paths","metadata":{}},{"cell_type":"code","source":"# Directories needed\nparanmt_dataset_dir = \"/kaggle/input/project-datasets/paranmt_filtered\"\nparaphrase_model_chkpts_dir =  \"/kaggle/working/\"\nfinal_paraphrase_model_dir = \"/content/drive/MyDrive/IRE/DVP/final_DVP\"","metadata":{"id":"uITAqdNQfHT1","execution":{"iopub.status.busy":"2023-11-18T18:25:05.537001Z","iopub.execute_input":"2023-11-18T18:25:05.537310Z","iopub.status.idle":"2023-11-18T18:25:05.552501Z","shell.execute_reply.started":"2023-11-18T18:25:05.537284Z","shell.execute_reply":"2023-11-18T18:25:05.551734Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Declaring Arguments","metadata":{}},{"cell_type":"code","source":"# Required Arguments\nargs_dir = {\n  \"save_steps\" : 1000, # can be changed\n  \"num_epochs\" : 3,\n  \"gradient_accumulation_steps\" : 2,\n  \"adam_epsilon\" : 1e-8,\n  \"warmup_steps\" : 0,\n  \"learning_rt\" : 5e-5,\n  \"max_grad_norm\" : 1.0,\n  \"data_dir\" : paranmt_dataset_dir,\n  \"model_type\" : \"gpt2\",\n  \"model_name\" : \"gpt2\",  # set to gtp2-large\n  \"train_batch_size\" : 5,\n  \"eval_batch_size\" : 5,\n  \"extra_embedding_dim\" : 768,\n  \"global_dense_feature_list\" : None # in file it will be saved with the value null; while reading take care of this thing\n}\n\nmodel_type = args_dir[\"model_type\"]\nmodel_name = args_dir[\"model_name\"]\ndata_dir = args_dir[\"data_dir\"]\nsave_steps = args_dir[\"save_steps\"]\nnum_epochs = args_dir[\"num_epochs\"]\ngradient_accumulation_steps = args_dir[\"gradient_accumulation_steps\"]\nadam_epsilon = args_dir[\"adam_epsilon\"]\nwarmup_steps = args_dir[\"warmup_steps\"]\ntrain_batch_size = args_dir[\"train_batch_size\"]\neval_batch_size = args_dir[\"eval_batch_size\"]\nlearning_rt = args_dir[\"learning_rt\"]\nextra_embedding_dim = args_dir[\"extra_embedding_dim\"] # Size of linear layer used for projecting extra embeddings.\nglobal_dense_feature_list = args_dir[\"global_dense_feature_list\"]\nmax_grad_norm = args_dir[\"max_grad_norm\"]","metadata":{"id":"l0SqfkAKe6XF","execution":{"iopub.status.busy":"2023-11-18T18:25:05.553725Z","iopub.execute_input":"2023-11-18T18:25:05.554077Z","iopub.status.idle":"2023-11-18T18:25:05.564964Z","shell.execute_reply.started":"2023-11-18T18:25:05.554046Z","shell.execute_reply":"2023-11-18T18:25:05.564049Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Choose device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_gpus = torch.cuda.device_count()\n\nprint(\"Device- \", device)\nprint(\"No. of GPUs- \", n_gpus)\n# print(device[0])\n# print(device[1])","metadata":{"id":"gKxaQf_vfY8x","outputId":"99bf37c2-c701-44db-b27a-f1b57a1146a9","execution":{"iopub.status.busy":"2023-11-18T18:25:05.566481Z","iopub.execute_input":"2023-11-18T18:25:05.566860Z","iopub.status.idle":"2023-11-18T18:25:05.636654Z","shell.execute_reply.started":"2023-11-18T18:25:05.566806Z","shell.execute_reply":"2023-11-18T18:25:05.635575Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Device-  cuda\nNo. of GPUs-  2\n","output_type":"stream"}]},{"cell_type":"code","source":"# Install Transformers\n!pip install transformers","metadata":{"id":"tO96sVnbfl3-","outputId":"ee95845e-dcf2-4aef-8f14-f7e3853daff1","execution":{"iopub.status.busy":"2023-11-18T18:25:05.637947Z","iopub.execute_input":"2023-11-18T18:25:05.638640Z","iopub.status.idle":"2023-11-18T18:25:18.950735Z","shell.execute_reply.started":"2023-11-18T18:25:05.638601Z","shell.execute_reply":"2023-11-18T18:25:18.949680Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Model Specifications and Training","metadata":{}},{"cell_type":"code","source":"# Initialize model classes variables\nMODEL_CLASSES = {\n    'gpt2': (GPT2Config, GPT2LMHeadModel, GPT2Tokenizer),\n}\nconfig_class, model_class, tokenizer_class = MODEL_CLASSES[model_type]\n\nprint(\"GPT2 Config class- \", config_class)\nprint(\"GPT2 Model class- \", model_class)\nprint(\"GPT2 Tokenizer class- \", tokenizer_class)","metadata":{"id":"cPYP-5aqfoUr","outputId":"7fff9dee-af25-4e12-ae2c-a963afd28b5d","execution":{"iopub.status.busy":"2023-11-18T18:25:18.954498Z","iopub.execute_input":"2023-11-18T18:25:18.954814Z","iopub.status.idle":"2023-11-18T18:25:18.961117Z","shell.execute_reply.started":"2023-11-18T18:25:18.954786Z","shell.execute_reply":"2023-11-18T18:25:18.960217Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"GPT2 Config class-  <class 'transformers.models.gpt2.configuration_gpt2.GPT2Config'>\nGPT2 Model class-  <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>\nGPT2 Tokenizer class-  <class 'transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer'>\n","output_type":"stream"}]},{"cell_type":"code","source":"# Init config\nconfig = config_class.from_pretrained(model_name)\nprint(\"GPT2Config loaded\")\n\n# Init model\nmodel = model_class.from_pretrained(model_name, config = config)\nprint(\"GPT2LMHeadModel loaded\")\n\n# Init tokenizer\ntokenizer = tokenizer_class.from_pretrained(model_name,do_lower_case = False)\nprint(\"GPT2Tokenizer loaded\")","metadata":{"id":"IkRbobfmgBqU","outputId":"26899ea5-be44-43b5-9682-ac947261af32","execution":{"iopub.status.busy":"2023-11-18T18:25:18.962253Z","iopub.execute_input":"2023-11-18T18:25:18.962546Z","iopub.status.idle":"2023-11-18T18:25:24.935857Z","shell.execute_reply.started":"2023-11-18T18:25:18.962520Z","shell.execute_reply":"2023-11-18T18:25:24.934885Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca8b8ca3118e417fa2975a8b227ed7ac"}},"metadata":{}},{"name":"stdout","text":"GPT2Config loaded\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d01794c98ea46578e82ea0d5b2af3ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e84fc3f19de46029c30ce3216d0553a"}},"metadata":{}},{"name":"stdout","text":"GPT2LMHeadModel loaded\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1612625b29c4c7282908bc43a8743ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"754d29eb9ff94e20819968be8de8667d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"baa0c9fa51b444ec9d7e3685541fdd49"}},"metadata":{}},{"name":"stdout","text":"GPT2Tokenizer loaded\n","output_type":"stream"}]},{"cell_type":"code","source":"# adding extra_dimension to config --- No need in DVP ---- Can be removed later\nconfig.extra_embedding_dim = extra_embedding_dim # don't know why we are using it; -- explore it","metadata":{"id":"XFclyWOSg0MK","execution":{"iopub.status.busy":"2023-11-18T18:25:24.937197Z","iopub.execute_input":"2023-11-18T18:25:24.937587Z","iopub.status.idle":"2023-11-18T18:25:24.942544Z","shell.execute_reply.started":"2023-11-18T18:25:24.937550Z","shell.execute_reply":"2023-11-18T18:25:24.941665Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Add special tokens to tokenizer\nSPECIAL_TOKENS = {\n    \"additional_special_tokens\": [\"<segment_1>\", \"<segment_2>\"],\n    \"pad_token\": \"<pad>\",\n    \"bos_token\": \"<bos>\",\n    \"eos_token\": \"<eos>\"\n}\ntokenizer.add_special_tokens(SPECIAL_TOKENS)\nprint(\"Special Tokens addded to tokenizer\")\n\nprint(\"Total tokens- \", len(tokenizer))","metadata":{"id":"kj8OLUpzhCwf","outputId":"602d45f6-8684-42ae-8dd6-c8994ef84b86","execution":{"iopub.status.busy":"2023-11-18T18:25:24.943892Z","iopub.execute_input":"2023-11-18T18:25:24.944242Z","iopub.status.idle":"2023-11-18T18:25:24.959737Z","shell.execute_reply.started":"2023-11-18T18:25:24.944206Z","shell.execute_reply":"2023-11-18T18:25:24.958810Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Special Tokens addded to tokenizer\nTotal tokens-  50262\n","output_type":"stream"}]},{"cell_type":"code","source":"# resize token embedding matrix to take care of special tokens added\nmodel.resize_token_embeddings(len(tokenizer)) # each token of size-> 1280(gpt2-large), 768(gpt2)","metadata":{"id":"XtfKi7BRhzzr","outputId":"8e1fa0b0-2220-4b2b-d750-aa8a6c8daa9d","execution":{"iopub.status.busy":"2023-11-18T18:25:24.961007Z","iopub.execute_input":"2023-11-18T18:25:24.961275Z","iopub.status.idle":"2023-11-18T18:25:25.626509Z","shell.execute_reply.started":"2023-11-18T18:25:24.961251Z","shell.execute_reply":"2023-11-18T18:25:25.625714Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Embedding(50262, 768)"},"metadata":{}}]},{"cell_type":"code","source":"# move model to device\nmodel.to(device)","metadata":{"id":"t9SyeahpiI70","outputId":"ead4d98d-12a0-4aa8-96d3-fffb1759780a","execution":{"iopub.status.busy":"2023-11-18T18:25:25.627590Z","iopub.execute_input":"2023-11-18T18:25:25.627873Z","iopub.status.idle":"2023-11-18T18:25:29.227309Z","shell.execute_reply.started":"2023-11-18T18:25:25.627848Z","shell.execute_reply":"2023-11-18T18:25:29.226296Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50262, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50262, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Init configs\n\nMAX_PARAPHRASE_LEN = 100\n\n# mainly to handle input\nINPUT_FORMAT_CONFIG = {\n    \"keys\": [\n        {\"key\": \"sent1_tokens\", \"position\": 3},\n        {\"key\": \"sent2_tokens\", \"position\": 4}\n    ],\n    \"max_prefix_length\": int(MAX_PARAPHRASE_LEN / 2),\n    \"max_suffix_length\": int(MAX_PARAPHRASE_LEN / 2)\n}","metadata":{"id":"_-U1rn6liN3f","execution":{"iopub.status.busy":"2023-11-18T18:25:29.228678Z","iopub.execute_input":"2023-11-18T18:25:29.229011Z","iopub.status.idle":"2023-11-18T18:25:29.234395Z","shell.execute_reply.started":"2023-11-18T18:25:29.228985Z","shell.execute_reply":"2023-11-18T18:25:29.233502Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Fn to convert example input to dictionary\ndef input_to_dict(config, sample, tokenizer):\n    example = {}\n\n    for inp_key in config[\"keys\"]:\n        val = sample[inp_key[\"position\"]]\n        example[inp_key[\"key\"]] = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(val))\n\n    return example","metadata":{"id":"vSeC0tS4jI5t","execution":{"iopub.status.busy":"2023-11-18T18:25:29.235543Z","iopub.execute_input":"2023-11-18T18:25:29.235822Z","iopub.status.idle":"2023-11-18T18:25:29.867634Z","shell.execute_reply.started":"2023-11-18T18:25:29.235797Z","shell.execute_reply":"2023-11-18T18:25:29.866548Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Preprocess input from paranmt\ndef preprocess(exp, tokenizer, config, do_tokenize=True):\n  MASK_TOKEN_ID = -100\n\n  max_prefix_len = config[\"max_prefix_length\"]\n  max_suffix_len = config[\"max_suffix_length\"]\n\n  if do_tokenize:\n    sent1 = np.array(exp[\"sent1_tokens\"])\n    sent2 = np.array(exp[\"sent2_tokens\"])\n\n  # truncate\n  if(len(sent1) > max_prefix_len):\n    sent1 = sent1[:max_prefix_len]\n\n  if(len(sent2) > max_suffix_len):\n    sent2 = sent2[:max_suffix_len]\n\n  # add padding; left padding to prefix and right padding to suffix\n  count_pad_tokens_prefix = max_prefix_len - len(sent1)\n  sent1 = np.pad(sent1, (count_pad_tokens_prefix, 0), constant_values = tokenizer.pad_token_id)\n\n  # add <eos> to suffix\n  sent2 = np.append(sent2, tokenizer.eos_token_id)\n\n  count_pad_tokens_suffix = (max_suffix_len + 1) - len(sent2)\n  sent2 = np.pad(sent2, (0, count_pad_tokens_suffix), constant_values = tokenizer.pad_token_id)\n\n  # sentence to input gpt2\n  sentence_to_input_gpt2 = np.concatenate([sent1, [tokenizer.bos_token_id], sent2]).astype(np.int64) # [sent1, <bos> sent2]\n\n  # label/gt to predict; -100 used for masking that input (in ground truth only)\n  gt = np.concatenate([\n      [MASK_TOKEN_ID for _ in sent1],\n      [MASK_TOKEN_ID],\n      [val if val != tokenizer.pad_token_id else MASK_TOKEN_ID for val in sent2]\n  ]).astype(np.int64)\n\n  # segment\n  segment = np.concatenate([\n      [tokenizer.additional_special_tokens_ids[0] for _ in sent1],\n      [tokenizer.additional_special_tokens_ids[1]],\n      [tokenizer.additional_special_tokens_ids[1] for _ in sent2]\n  ]).astype(np.int64)\n\n  exp[\"prefix_sent\"] = sent1\n  exp[\"suffix_sent\"] = sent2\n\n  exp[\"input\"] = sentence_to_input_gpt2\n  exp[\"label\"] = gt\n  exp[\"segment\"] = segment\n\n  return exp","metadata":{"id":"W3gcYYjhkM3e","execution":{"iopub.status.busy":"2023-11-18T18:25:29.869346Z","iopub.execute_input":"2023-11-18T18:25:29.869669Z","iopub.status.idle":"2023-11-18T18:25:29.939070Z","shell.execute_reply.started":"2023-11-18T18:25:29.869642Z","shell.execute_reply":"2023-11-18T18:25:29.938043Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# DVP dataset\nclass Diverse_Paraphraser_Dataset(Dataset):\n    def __init__(self, paranmt_dataset_dir, config, tokenizer, limit_examples = None, evaluate = False, split_type = \"train\"):\n      self.config = config\n      self.examples = []\n      file_to_read = paranmt_dataset_dir + \"/\" +split_type + \".pickle\"\n\n      with open(file_to_read, \"rb\") as data_to_read:\n        split_data = pickle.load(data_to_read)\n\n      print(\"\\n\\n Original raw data in loaded pickle file- \", split_data[0])\n\n      print(\"\\n\\n Converting samples to dictionary form...\")\n      self.examples = [input_to_dict(self.config, sample, tokenizer) for sample in tqdm.tqdm(split_data)]\n\n      print(\"\\n\\n After conversion- \", self.examples[0])\n\n      # Reduce dataset if required\n      if limit_examples != None:\n        self.examples = self.examples[:limit_examples]\n\n      print(\"\\n\\n Doing Preprocess each sample\")\n      # do Preprocessing in each of the converted samples\n      self.examples = [preprocess(exp, tokenizer, self.config, do_tokenize = True) for exp in self.examples]\n\n      print(\"\\n\\n After preprocessing- \", self.examples[0])\n\n    def __len__(self):\n        return len(self.examples)\n\n    def __getitem__(self, idx):\n      sentence = self.examples[idx][\"input\"]\n      label = self.examples[idx][\"label\"]\n      segment = self.examples[idx][\"segment\"]\n      context_len = self.config[\"max_prefix_length\"] + 1 # (+1) for <bos>\n\n      return {\n          \"sample_number\": idx,\n          \"sentence\": torch.tensor(sentence),\n          \"label\": torch.tensor(label),\n          \"segment\": torch.tensor(segment)\n      }","metadata":{"id":"M0F7K1d2kkFW","execution":{"iopub.status.busy":"2023-11-18T18:25:29.942703Z","iopub.execute_input":"2023-11-18T18:25:29.943072Z","iopub.status.idle":"2023-11-18T18:25:30.030996Z","shell.execute_reply.started":"2023-11-18T18:25:29.943045Z","shell.execute_reply":"2023-11-18T18:25:30.029879Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# create DVP dataset\ntrain_dataset = Diverse_Paraphraser_Dataset(paranmt_dataset_dir,\n                                            INPUT_FORMAT_CONFIG,\n                                            tokenizer,\n                                            limit_examples = None,\n                                            evaluate = False, split_type = \"train\")\nprint(\"\\n\\n DVP Dataset created\")","metadata":{"id":"14PeAYRenzaj","outputId":"92f56ad3-d32c-4a81-aa31-dcdb7abf6216","execution":{"iopub.status.busy":"2023-11-18T18:25:30.032573Z","iopub.execute_input":"2023-11-18T18:25:30.032896Z","iopub.status.idle":"2023-11-18T18:26:37.486406Z","shell.execute_reply.started":"2023-11-18T18:25:30.032863Z","shell.execute_reply":"2023-11-18T18:26:37.485437Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"\n\n Original raw data in loaded pickle file-  ('S > NP VP .', 'S > SBAR , NP VP .', False, 'Mr. Whetstone is goingto speak to you after I finish.', \"after I'm done, Mr. Whetstone will be speaking.\", (0.3, 0.375, 0.33333333333333326), (-0.33333333333333337, False), 2, ('en', 'en'))\n\n\n Converting samples to dictionary form...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 73062/73062 [00:24<00:00, 3003.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n\n After conversion-  {'sent1_tokens': [5246, 13, 370, 3202, 6440, 318, 1016, 1462, 2740, 284, 345, 706, 314, 5461, 13], 'sent2_tokens': [8499, 314, 1101, 1760, 11, 1770, 13, 370, 3202, 6440, 481, 307, 5486, 13]}\n\n\n Doing Preprocess each sample\n\n\n After preprocessing-  {'sent1_tokens': [5246, 13, 370, 3202, 6440, 318, 1016, 1462, 2740, 284, 345, 706, 314, 5461, 13], 'sent2_tokens': [8499, 314, 1101, 1760, 11, 1770, 13, 370, 3202, 6440, 481, 307, 5486, 13], 'prefix_sent': array([50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,  5246,\n          13,   370,  3202,  6440,   318,  1016,  1462,  2740,   284,\n         345,   706,   314,  5461,    13]), 'suffix_sent': array([ 8499,   314,  1101,  1760,    11,  1770,    13,   370,  3202,\n        6440,   481,   307,  5486,    13, 50261, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259]), 'input': array([50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,  5246,\n          13,   370,  3202,  6440,   318,  1016,  1462,  2740,   284,\n         345,   706,   314,  5461,    13, 50260,  8499,   314,  1101,\n        1760,    11,  1770,    13,   370,  3202,  6440,   481,   307,\n        5486,    13, 50261, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259]), 'label': array([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n        -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n        -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n        -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n        -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n        -100,  -100,  -100,  -100,  -100,  -100,  8499,   314,  1101,\n        1760,    11,  1770,    13,   370,  3202,  6440,   481,   307,\n        5486,    13, 50261,  -100,  -100,  -100,  -100,  -100,  -100,\n        -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n        -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n        -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n        -100,  -100,  -100]), 'segment': array([50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n       50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n       50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n       50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n       50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n       50257, 50257, 50257, 50257, 50257, 50258, 50258, 50258, 50258,\n       50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n       50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n       50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n       50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n       50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n       50258, 50258, 50258])}\n\n\n DVP Dataset created\n","output_type":"stream"}]},{"cell_type":"code","source":"# create dataloader\ntrain_sampler = RandomSampler(train_dataset)\ntrain_dataloader = DataLoader(train_dataset, sampler = train_sampler, batch_size = train_batch_size)\n\nprint(\"DVP train dataloader created\")","metadata":{"id":"nhhZkUNAqfY3","outputId":"61c7fea8-e41f-4a1b-f646-375478d426ac","execution":{"iopub.status.busy":"2023-11-18T18:26:37.487919Z","iopub.execute_input":"2023-11-18T18:26:37.488597Z","iopub.status.idle":"2023-11-18T18:26:37.494406Z","shell.execute_reply.started":"2023-11-18T18:26:37.488555Z","shell.execute_reply":"2023-11-18T18:26:37.493537Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"DVP train dataloader created\n","output_type":"stream"}]},{"cell_type":"code","source":"# Total steps needed\nt_total = len(train_dataloader) // gradient_accumulation_steps * num_epochs\n\n# setting up the optimizer & learning rate schedulers\nno_decay = ['bias', 'LayerNorm.weight', 'layer_norm.weight']\ngrouped_parameters = [\n    {\n        'params': [p for n, p in model.named_parameters()],\n        'weight_decay': 0.0\n    }\n]\n\noptimizer = AdamW(grouped_parameters, lr = float(learning_rt), eps = adam_epsilon)\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = warmup_steps, num_training_steps = t_total)\n\nprint(\"Adam Optimizer and learning rate scheduler instantiated\")","metadata":{"id":"Ia4kAjeFpiLk","outputId":"e8870e1d-6778-4876-876a-7ae0504ebefd","execution":{"iopub.status.busy":"2023-11-18T18:26:37.495509Z","iopub.execute_input":"2023-11-18T18:26:37.495763Z","iopub.status.idle":"2023-11-18T18:26:37.518210Z","shell.execute_reply.started":"2023-11-18T18:26:37.495739Z","shell.execute_reply":"2023-11-18T18:26:37.517143Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Adam Optimizer and learning rate scheduler instantiated\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Training meta Information\nprint(\"Num of examples- \", len(train_dataset))\nprint(\"Num of epochs- \", num_epochs)\nprint(\"Batch size- \", train_batch_size)\nprint(\"Gradient acculmulation steps- \", gradient_accumulation_steps)\nprint(\"Total optimization steps- \", t_total)","metadata":{"id":"HyrTBG9drl0Z","outputId":"96efbe6f-22d0-4208-8097-73921fc03020","execution":{"iopub.status.busy":"2023-11-18T18:26:37.519670Z","iopub.execute_input":"2023-11-18T18:26:37.519946Z","iopub.status.idle":"2023-11-18T18:26:37.525271Z","shell.execute_reply.started":"2023-11-18T18:26:37.519922Z","shell.execute_reply":"2023-11-18T18:26:37.524413Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Num of examples-  73062\nNum of epochs-  3\nBatch size-  5\nGradient acculmulation steps-  2\nTotal optimization steps-  21918\n","output_type":"stream"}]},{"cell_type":"code","source":"# zero out all the gradients\nmodel.zero_grad()","metadata":{"id":"2QZsxWQ3r0ba","execution":{"iopub.status.busy":"2023-11-18T18:26:37.526261Z","iopub.execute_input":"2023-11-18T18:26:37.526504Z","iopub.status.idle":"2023-11-18T18:26:37.534475Z","shell.execute_reply.started":"2023-11-18T18:26:37.526482Z","shell.execute_reply":"2023-11-18T18:26:37.533767Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Fn to save checkpoints\ndef save_model(model, tokenizer, chkpt_dir, args_dir):\n  if not os.path.exists(chkpt_dir):\n    os.makedirs(chkpt_dir)\n  print(\"Directory created for new checkpt to save\")\n\n  model.save_pretrained(chkpt_dir)\n  tokenizer.save_pretrained(chkpt_dir)\n  print(\"Model and tokenizer saved\")\n\n  # save training arguments also\n  with open(chkpt_dir + \"/my_args.json\", \"w\") as json_file:\n    json.dump(args_dir, json_file)\n  print(\"Training arguments saved\")\n\n  with open(os.path.join(chkpt_dir, \"global_step.txt\"), \"w\") as f:\n    f.write(str(global_step) + \"\\n\")\n  print(\"Global step file saved\")\n\n  print(\"Checkpint saving process done..\")","metadata":{"id":"-tmbp1HotBjR","execution":{"iopub.status.busy":"2023-11-18T18:26:37.539716Z","iopub.execute_input":"2023-11-18T18:26:37.540068Z","iopub.status.idle":"2023-11-18T18:26:37.546896Z","shell.execute_reply.started":"2023-11-18T18:26:37.540043Z","shell.execute_reply":"2023-11-18T18:26:37.545876Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\nglobal_step = 0\ntrain_loss_val = 0.0\nchkpts_dir_name = []\n\n# start training\ntrain_iterator = trange(int(num_epochs), desc = \"Epoch\")\nfor epoch in train_iterator:\n#     epoch_iterator = tqdm(train_dataloader, desc = \"Iteration\")\n#     epoch_iterator = tqdm(train_dataloader, desc = \"Iteration\")\n\n    for batch_idx, batch in enumerate(train_dataloader):\n      sentences = batch[\"sentence\"].to(device)\n      labels = batch[\"label\"].to(device)\n      segments = batch[\"segment\"].to(device)\n      model.train()\n\n      outputs = model(input_ids=sentences, token_type_ids=segments, labels=labels)\n#       print(\"Got logits and loss\")\n\n      loss = outputs.loss\n      loss = loss / gradient_accumulation_steps\n      train_loss_val += loss.item()\n\n      loss.backward()\n\n      if (((batch_idx + 1) % gradient_accumulation_steps) == 0):\n#         print(\"Moved 1 step\")\n        F.clip_grad_norm_(model.parameters(), max_grad_norm)\n        optimizer.step()\n        scheduler.step()\n\n        model.zero_grad()\n        global_step += 1\n\n        if (global_step % save_steps == 0):\n          # save checkpoint here\n          print(\"Saving new checkpoint\")\n          chkpt_dir = paraphrase_model_chkpts_dir + \"/dvp_chkpt_\"+str(global_step)\n          chkpts_dir_name.append(\"dvp_chkpt_\"+str(global_step))\n\n          save_model(model, tokenizer, chkpt_dir, args_dir)\n#       break","metadata":{"id":"iFVD4S4Wr7O7","outputId":"e00aa8c9-4111-40e4-feb0-2a480cae1bae","execution":{"iopub.status.busy":"2023-11-18T18:26:37.547930Z","iopub.execute_input":"2023-11-18T18:26:37.548209Z","iopub.status.idle":"2023-11-18T20:19:58.673243Z","shell.execute_reply.started":"2023-11-18T18:26:37.548185Z","shell.execute_reply":"2023-11-18T20:19:58.672294Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Saving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\nSaving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\nSaving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\nSaving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\nSaving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\nSaving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\nSaving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  33%|███▎      | 1/3 [37:40<1:15:21, 2260.86s/it]","output_type":"stream"},{"name":"stdout","text":"Saving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\nSaving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\nSaving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\nSaving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\nSaving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\nSaving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\nSaving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  67%|██████▋   | 2/3 [1:15:32<37:47, 2267.10s/it]","output_type":"stream"},{"name":"stdout","text":"Saving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\nSaving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\nSaving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\nSaving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\nSaving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\nSaving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\nSaving new checkpoint\nDirectory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 100%|██████████| 3/3 [1:53:21<00:00, 2267.04s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Average train_loss per step\nglobal_step, tr_loss = global_step, train_loss_val / (global_step) # +1 only while testing\nprint(\"Final Global step- \", global_step)\nprint(\"Average training loss per step- \", tr_loss)","metadata":{"id":"YtVhuy1qxcW1","outputId":"ecf51220-5b32-4a1c-dbc8-444a10623e15","execution":{"iopub.status.busy":"2023-11-18T20:19:58.674497Z","iopub.execute_input":"2023-11-18T20:19:58.674786Z","iopub.status.idle":"2023-11-18T20:19:58.679954Z","shell.execute_reply.started":"2023-11-18T20:19:58.674760Z","shell.execute_reply":"2023-11-18T20:19:58.679114Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Final Global step-  21918\nAverage training loss per step-  1.8089590687632768\n","output_type":"stream"}]},{"cell_type":"code","source":"# save the last model also\n\nchkpt_dir = paraphrase_model_chkpts_dir + \"/dvp_chkpt_\"+str(global_step)\nchkpts_dir_name.append(\"dvp_chkpt_\"+str(global_step))\n\nsave_model(model, tokenizer, chkpt_dir, args_dir)\n\nprint(\"Last model state saved\")","metadata":{"id":"nZJlf59JzZ9n","outputId":"e1040c0c-29c2-463e-fd92-d4cb7b764ebb","execution":{"iopub.status.busy":"2023-11-18T20:19:58.681148Z","iopub.execute_input":"2023-11-18T20:19:58.681463Z","iopub.status.idle":"2023-11-18T20:20:00.038890Z","shell.execute_reply.started":"2023-11-18T20:19:58.681427Z","shell.execute_reply":"2023-11-18T20:20:00.037883Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Directory created for new checkpt to save\nModel and tokenizer saved\nTraining arguments saved\nGlobal step file saved\nCheckpint saving process done..\nLast model state saved\n","output_type":"stream"}]},{"cell_type":"code","source":"# Till now,\n# DVP trained -> checkpoints saved -> Last model state saved\nprint(\"Checkpoints saved with the name- \", chkpts_dir_name)","metadata":{"id":"IrmS18joz0df","outputId":"5d1af014-a91b-4d44-df76-49bf8ec2270e","execution":{"iopub.status.busy":"2023-11-18T20:20:00.040148Z","iopub.execute_input":"2023-11-18T20:20:00.040455Z","iopub.status.idle":"2023-11-18T20:20:00.045239Z","shell.execute_reply.started":"2023-11-18T20:20:00.040422Z","shell.execute_reply":"2023-11-18T20:20:00.044336Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Checkpoints saved with the name-  ['dvp_chkpt_1000', 'dvp_chkpt_2000', 'dvp_chkpt_3000', 'dvp_chkpt_4000', 'dvp_chkpt_5000', 'dvp_chkpt_6000', 'dvp_chkpt_7000', 'dvp_chkpt_8000', 'dvp_chkpt_9000', 'dvp_chkpt_10000', 'dvp_chkpt_11000', 'dvp_chkpt_12000', 'dvp_chkpt_13000', 'dvp_chkpt_14000', 'dvp_chkpt_15000', 'dvp_chkpt_16000', 'dvp_chkpt_17000', 'dvp_chkpt_18000', 'dvp_chkpt_19000', 'dvp_chkpt_20000', 'dvp_chkpt_21000', 'dvp_chkpt_21918']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Selecting Best Models from the saved Checkpoints Via Perplexity","metadata":{}},{"cell_type":"code","source":"# Start Evaluation\nprint(\"Starting Evaluation of DVP on dev data based on perplexity\")","metadata":{"id":"OaYHCRWO0Vmq","outputId":"ee4f2aa2-ee03-41f6-acaa-44ccd3eacfac","execution":{"iopub.status.busy":"2023-11-18T20:20:00.046586Z","iopub.execute_input":"2023-11-18T20:20:00.047169Z","iopub.status.idle":"2023-11-18T20:20:00.060456Z","shell.execute_reply.started":"2023-11-18T20:20:00.047134Z","shell.execute_reply":"2023-11-18T20:20:00.059576Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Starting Evaluation of DVP on dev data based on perplexity\n","output_type":"stream"}]},{"cell_type":"code","source":"# Get validation dataset and dataloader\nimport tqdm\nval_dataset = Diverse_Paraphraser_Dataset(paranmt_dataset_dir,\n                                            INPUT_FORMAT_CONFIG,\n                                            tokenizer,\n                                            limit_examples = None,\n                                            evaluate = True, split_type = \"dev\")\n\nval_sampler = SequentialSampler(val_dataset)\nval_dataloader = DataLoader(val_dataset, sampler = val_sampler, batch_size = eval_batch_size)\n\nprint(\"Validation dataset and dataloader created\")","metadata":{"id":"cOaPH6go0yUj","outputId":"b1a6d187-4b14-49cd-adf6-866856b1df7b","execution":{"iopub.status.busy":"2023-11-18T20:20:00.061733Z","iopub.execute_input":"2023-11-18T20:20:00.062058Z","iopub.status.idle":"2023-11-18T20:20:01.420531Z","shell.execute_reply.started":"2023-11-18T20:20:00.062009Z","shell.execute_reply":"2023-11-18T20:20:01.419409Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"\n\n Original raw data in loaded pickle file-  ('FRAG > CD , CD , CD , CD , CC VP .', 'FRAG > CD , CD , CD , CD CC VBP .', False, '1, 2, 3, 4, and get the hell out of there!', 'one, two, three, four and fall!', (0.1, 0.16666666666666666, 0.125), (-1.0, True), 2, ('en', 'en'))\n\n\n Converting samples to dictionary form...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1492/1492 [00:00<00:00, 3256.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n\n After conversion-  {'sent1_tokens': [16, 11, 362, 11, 513, 11, 604, 11, 290, 651, 262, 5968, 503, 286, 612, 0], 'sent2_tokens': [505, 11, 734, 11, 1115, 11, 1440, 290, 2121, 0]}\n\n\n Doing Preprocess each sample\n\n\n After preprocessing-  {'sent1_tokens': [16, 11, 362, 11, 513, 11, 604, 11, 290, 651, 262, 5968, 503, 286, 612, 0], 'sent2_tokens': [505, 11, 734, 11, 1115, 11, 1440, 290, 2121, 0], 'prefix_sent': array([50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259,    16,    11,\n         362,    11,   513,    11,   604,    11,   290,   651,   262,\n        5968,   503,   286,   612,     0]), 'suffix_sent': array([  505,    11,   734,    11,  1115,    11,  1440,   290,  2121,\n           0, 50261, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259]), 'input': array([50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259,    16,    11,\n         362,    11,   513,    11,   604,    11,   290,   651,   262,\n        5968,   503,   286,   612,     0, 50260,   505,    11,   734,\n          11,  1115,    11,  1440,   290,  2121,     0, 50261, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n       50259, 50259, 50259]), 'label': array([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n        -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n        -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n        -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n        -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n        -100,  -100,  -100,  -100,  -100,  -100,   505,    11,   734,\n          11,  1115,    11,  1440,   290,  2121,     0, 50261,  -100,\n        -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n        -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n        -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n        -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n        -100,  -100,  -100]), 'segment': array([50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n       50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n       50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n       50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n       50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n       50257, 50257, 50257, 50257, 50257, 50258, 50258, 50258, 50258,\n       50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n       50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n       50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n       50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n       50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n       50258, 50258, 50258])}\nValidation dataset and dataloader created\n","output_type":"stream"}]},{"cell_type":"code","source":"# Validation meta Information\nprint(\"Num of examples- \", len(val_dataset))\nprint(\"Batch size- \", eval_batch_size)","metadata":{"id":"H3w1t98H2d-U","outputId":"3ecb3341-f04e-429a-ff63-f3728afe3aa1","execution":{"iopub.status.busy":"2023-11-18T20:20:01.422001Z","iopub.execute_input":"2023-11-18T20:20:01.422473Z","iopub.status.idle":"2023-11-18T20:20:01.428632Z","shell.execute_reply.started":"2023-11-18T20:20:01.422428Z","shell.execute_reply":"2023-11-18T20:20:01.427594Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Num of examples-  1492\nBatch size-  5\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fn to evaluate on a DVP checkpoint\ndef evaluate(model, tokenizer, chkpt_dir_name, val_dataloader):\n  val_loss = 0.0\n  model.eval()\n\n  for i, batch in enumerate(val_dataloader):\n    sentences = batch[\"sentence\"].to(device)\n    labels = batch[\"label\"].to(device)\n    segments = batch[\"segment\"].to(device)\n\n    with torch.no_grad():\n      op = model(input_ids=sentences, token_type_ids=segments, labels=labels)\n      loss_val = op.loss.item()\n\n    val_loss += loss_val\n#     break\n\n  avg_val_loss = val_loss / (i + 1) # per batch average loss\n  perplexity = torch.exp(torch.tensor(avg_val_loss)) # perplexity of exp(avg_loss)\n\n  return perplexity","metadata":{"id":"FlEXSNJ12zDx","execution":{"iopub.status.busy":"2023-11-18T20:20:01.430157Z","iopub.execute_input":"2023-11-18T20:20:01.430569Z","iopub.status.idle":"2023-11-18T20:20:01.440033Z","shell.execute_reply.started":"2023-11-18T20:20:01.430533Z","shell.execute_reply":"2023-11-18T20:20:01.439127Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"chkpts_dir_name","metadata":{"id":"6B3KYaPD39C3","outputId":"9df6797f-408b-48e1-aeae-c06265e6c393","execution":{"iopub.status.busy":"2023-11-18T20:20:01.441085Z","iopub.execute_input":"2023-11-18T20:20:01.441351Z","iopub.status.idle":"2023-11-18T20:20:01.452648Z","shell.execute_reply.started":"2023-11-18T20:20:01.441323Z","shell.execute_reply":"2023-11-18T20:20:01.451734Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"['dvp_chkpt_1000',\n 'dvp_chkpt_2000',\n 'dvp_chkpt_3000',\n 'dvp_chkpt_4000',\n 'dvp_chkpt_5000',\n 'dvp_chkpt_6000',\n 'dvp_chkpt_7000',\n 'dvp_chkpt_8000',\n 'dvp_chkpt_9000',\n 'dvp_chkpt_10000',\n 'dvp_chkpt_11000',\n 'dvp_chkpt_12000',\n 'dvp_chkpt_13000',\n 'dvp_chkpt_14000',\n 'dvp_chkpt_15000',\n 'dvp_chkpt_16000',\n 'dvp_chkpt_17000',\n 'dvp_chkpt_18000',\n 'dvp_chkpt_19000',\n 'dvp_chkpt_20000',\n 'dvp_chkpt_21000',\n 'dvp_chkpt_21918']"},"metadata":{}}]},{"cell_type":"code","source":"#Workarounds to load the checkpoints\nchkpts_dir_name = ['dvp_chkpt_1000','dvp_chkpt_2000','dvp_chkpt_3000','dvp_chkpt_4000','dvp_chkpt_5000','dvp_chkpt_6000','dvp_chkpt_8000','dvp_chkpt_9000','dvp_chkpt_10000','dvp_chkpt_11000','dvp_chkpt_12000','dvp_chkpt_13000','dvp_chkpt_14000','dvp_chkpt_15000','dvp_chkpt_16000','dvp_chkpt_17000','dvp_chkpt_18000','dvp_chkpt_19000']","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:20:01.453765Z","iopub.execute_input":"2023-11-18T20:20:01.454193Z","iopub.status.idle":"2023-11-18T20:20:01.461873Z","shell.execute_reply.started":"2023-11-18T20:20:01.454161Z","shell.execute_reply":"2023-11-18T20:20:01.460967Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Start evaluating the checkpoints on dev data and using perplexity as a measure\nperplexity_list = []\n\nfor chkpt_name in chkpts_dir_name:\n  # load chkpoint\n  chkpt_to_load = paraphrase_model_chkpts_dir + \"/\" + chkpt_name\n  model = model_class.from_pretrained(chkpt_to_load)\n  tokenizer = tokenizer_class.from_pretrained(chkpt_to_load, do_lower_case = True)\n  model.to(device)\n  print(\"Checkpoint- \" + chkpt_name + \" loaded\")\n\n  # evaluate loaded\n  print(\"Evaluating on loaded checkpoint\")\n  perplexity = evaluate(model, tokenizer, chkpt_dir, val_dataloader)\n  perplexity_list.append((chkpt_name, perplexity))\n\nprint(\"DVP evaluated on all the saved checkpoints\")","metadata":{"id":"BDyqQ5HL3git","outputId":"cbf5c3be-1ba4-4d7a-8a55-85ebbb64aa02","execution":{"iopub.status.busy":"2023-11-18T20:20:01.463083Z","iopub.execute_input":"2023-11-18T20:20:01.463891Z","iopub.status.idle":"2023-11-18T20:24:45.058419Z","shell.execute_reply.started":"2023-11-18T20:20:01.463857Z","shell.execute_reply":"2023-11-18T20:24:45.057343Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Checkpoint- dvp_chkpt_1000 loaded\nEvaluating on loaded checkpoint\n","output_type":"stream"},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Checkpoint- dvp_chkpt_2000 loaded\nEvaluating on loaded checkpoint\n","output_type":"stream"},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Checkpoint- dvp_chkpt_3000 loaded\nEvaluating on loaded checkpoint\n","output_type":"stream"},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Checkpoint- dvp_chkpt_4000 loaded\nEvaluating on loaded checkpoint\n","output_type":"stream"},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Checkpoint- dvp_chkpt_5000 loaded\nEvaluating on loaded checkpoint\n","output_type":"stream"},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Checkpoint- dvp_chkpt_6000 loaded\nEvaluating on loaded checkpoint\n","output_type":"stream"},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Checkpoint- dvp_chkpt_8000 loaded\nEvaluating on loaded checkpoint\n","output_type":"stream"},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Checkpoint- dvp_chkpt_9000 loaded\nEvaluating on loaded checkpoint\n","output_type":"stream"},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Checkpoint- dvp_chkpt_10000 loaded\nEvaluating on loaded checkpoint\n","output_type":"stream"},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Checkpoint- dvp_chkpt_11000 loaded\nEvaluating on loaded checkpoint\n","output_type":"stream"},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Checkpoint- dvp_chkpt_12000 loaded\nEvaluating on loaded checkpoint\n","output_type":"stream"},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Checkpoint- dvp_chkpt_13000 loaded\nEvaluating on loaded checkpoint\n","output_type":"stream"},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Checkpoint- dvp_chkpt_14000 loaded\nEvaluating on loaded checkpoint\n","output_type":"stream"},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Checkpoint- dvp_chkpt_15000 loaded\nEvaluating on loaded checkpoint\n","output_type":"stream"},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Checkpoint- dvp_chkpt_16000 loaded\nEvaluating on loaded checkpoint\n","output_type":"stream"},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Checkpoint- dvp_chkpt_17000 loaded\nEvaluating on loaded checkpoint\n","output_type":"stream"},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Checkpoint- dvp_chkpt_18000 loaded\nEvaluating on loaded checkpoint\n","output_type":"stream"},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Checkpoint- dvp_chkpt_19000 loaded\nEvaluating on loaded checkpoint\nDVP evaluated on all the saved checkpoints\n","output_type":"stream"}]},{"cell_type":"code","source":"# Sort perplexity list in increasing order to get best model\nperplexity_list.sort(key=lambda x: x[1].item())\ntop_chkpt_name = perplexity_list[0][0]\n\nprint(\"Top performing checkpoint is- \", top_chkpt_name)","metadata":{"id":"qsM1BiAh5GdO","outputId":"a3d0fc98-b39e-4cee-db1d-1805993ec72c","execution":{"iopub.status.busy":"2023-11-18T20:24:45.060477Z","iopub.execute_input":"2023-11-18T20:24:45.060927Z","iopub.status.idle":"2023-11-18T20:24:45.067095Z","shell.execute_reply.started":"2023-11-18T20:24:45.060884Z","shell.execute_reply":"2023-11-18T20:24:45.066145Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Top performing checkpoint is-  dvp_chkpt_14000\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluation on dev data done","metadata":{"id":"AUBwktL85dve","execution":{"iopub.status.busy":"2023-11-18T20:24:45.068433Z","iopub.execute_input":"2023-11-18T20:24:45.068900Z","iopub.status.idle":"2023-11-18T20:24:45.078508Z","shell.execute_reply.started":"2023-11-18T20:24:45.068855Z","shell.execute_reply":"2023-11-18T20:24:45.077650Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"final_paraphrase_model_dir = \"/kaggle/working/DVP/final_DVP\"","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:36:56.004856Z","iopub.execute_input":"2023-11-18T20:36:56.005875Z","iopub.status.idle":"2023-11-18T20:36:56.010983Z","shell.execute_reply.started":"2023-11-18T20:36:56.005816Z","shell.execute_reply":"2023-11-18T20:36:56.009910Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# move top performing checkpoint to other final_paraphrase_model dir\ncopy_cmd = \"cp -r {}  {}\".format(paraphrase_model_chkpts_dir   + top_chkpt_name, final_paraphrase_model_dir)\ncopy_cmd","metadata":{"id":"to0orJ_n84eu","outputId":"500f4975-4783-439e-cd34-331abf67d69d","execution":{"iopub.status.busy":"2023-11-18T20:39:56.015735Z","iopub.execute_input":"2023-11-18T20:39:56.016148Z","iopub.status.idle":"2023-11-18T20:39:56.023146Z","shell.execute_reply.started":"2023-11-18T20:39:56.016117Z","shell.execute_reply":"2023-11-18T20:39:56.022155Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"'cp -r /kaggle/working/dvp_chkpt_14000  /kaggle/working/DVP/final_DVP'"},"metadata":{}}]},{"cell_type":"code","source":"# do copy to some other location\nsubprocess.check_output(copy_cmd, shell=True)\nprint(\"Copied successfully..!!\")","metadata":{"id":"TeqNfl2C9-mC","outputId":"ab2c9517-af0c-481f-f928-69bdc517485d","execution":{"iopub.status.busy":"2023-11-18T20:39:57.226794Z","iopub.execute_input":"2023-11-18T20:39:57.227194Z","iopub.status.idle":"2023-11-18T20:39:57.680418Z","shell.execute_reply.started":"2023-11-18T20:39:57.227160Z","shell.execute_reply":"2023-11-18T20:39:57.679264Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Copied successfully..!!\n","output_type":"stream"}]},{"cell_type":"code","source":"# just to verify that copied model is loading correctly or not\nchkpt_to_load = \"/kaggle/working/DVP/final_DVP/dvp_chkpt_14000\"\nmodel = model_class.from_pretrained(chkpt_to_load)\ntokenizer = tokenizer_class.from_pretrained(chkpt_to_load, do_lower_case = True)\n\nprint(\"Model loaded successfully..!!\")","metadata":{"id":"R7h4Cz90-Y5g","outputId":"a6fbdd3c-c71b-4444-c50c-8329ec841464","execution":{"iopub.status.busy":"2023-11-18T20:41:44.281972Z","iopub.execute_input":"2023-11-18T20:41:44.282412Z","iopub.status.idle":"2023-11-18T20:41:46.391412Z","shell.execute_reply.started":"2023-11-18T20:41:44.282378Z","shell.execute_reply":"2023-11-18T20:41:46.390318Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Model loaded successfully..!!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### CODE TO ZIP MODELS FOR DOWNLOAD","metadata":{}},{"cell_type":"code","source":"!zip -r last.zip /kaggle/working/dvp_chkpt_21918","metadata":{"id":"iU9m5Qyj_ne9","execution":{"iopub.status.busy":"2023-11-18T20:44:02.647776Z","iopub.execute_input":"2023-11-18T20:44:02.648539Z","iopub.status.idle":"2023-11-18T20:44:30.644486Z","shell.execute_reply.started":"2023-11-18T20:44:02.648493Z","shell.execute_reply":"2023-11-18T20:44:30.643425Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/dvp_chkpt_21918/ (stored 0%)\n  adding: kaggle/working/dvp_chkpt_21918/config.json (deflated 51%)\n  adding: kaggle/working/dvp_chkpt_21918/model.safetensors (deflated 7%)\n  adding: kaggle/working/dvp_chkpt_21918/added_tokens.json (deflated 45%)\n  adding: kaggle/working/dvp_chkpt_21918/special_tokens_map.json (deflated 79%)\n  adding: kaggle/working/dvp_chkpt_21918/global_step.txt (stored 0%)\n  adding: kaggle/working/dvp_chkpt_21918/my_args.json (deflated 40%)\n  adding: kaggle/working/dvp_chkpt_21918/tokenizer_config.json (deflated 77%)\n  adding: kaggle/working/dvp_chkpt_21918/vocab.json (deflated 68%)\n  adding: kaggle/working/dvp_chkpt_21918/generation_config.json (deflated 24%)\n  adding: kaggle/working/dvp_chkpt_21918/merges.txt (deflated 53%)\n","output_type":"stream"}]},{"cell_type":"code","source":"# !kaggle kernels output -p /kaggle/working -m file.zip","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:24:45.875984Z","iopub.status.idle":"2023-11-18T20:24:45.876357Z","shell.execute_reply.started":"2023-11-18T20:24:45.876191Z","shell.execute_reply":"2023-11-18T20:24:45.876208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# os.chdir(r'/kaggle/working')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:24:45.878146Z","iopub.status.idle":"2023-11-18T20:24:45.878464Z","shell.execute_reply.started":"2023-11-18T20:24:45.878310Z","shell.execute_reply":"2023-11-18T20:24:45.878324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'last.zip')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:45:38.848611Z","iopub.execute_input":"2023-11-18T20:45:38.849126Z","iopub.status.idle":"2023-11-18T20:45:38.857156Z","shell.execute_reply.started":"2023-11-18T20:45:38.849085Z","shell.execute_reply":"2023-11-18T20:45:38.856212Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/last.zip","text/html":"<a href='last.zip' target='_blank'>last.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}